# Practical Usage Examples - Glances MCP

This guide presents concrete examples of using the Glances MCP server with Claude.

## ğŸ¯ Scenario 1: Daily Monitoring

### Example 1.1: Morning Check-up

**You**:
```
Good morning Claude! Can you give me a status report on my server this morning?
```

**Claude**:
```
Good morning! Here's your server status this morning:

âœ… OVERALL STATUS: Healthy

ğŸ“Š KEY METRICS:
â€¢ CPU: 12% usage (4 cores)
  - User: 8%, System: 3%, Idle: 89%
  - Load average: 0.45, 0.52, 0.48 (1/5/15 min)

â€¢ MEMORY: 8.2 GB / 16 GB (51%)
  - Available: 7.8 GB
  - Swap: 512 MB / 4 GB (12%)

â€¢ DISKS:
  - / (sda1): 285 GB / 500 GB (57%) âœ…
  - /home (sda2): 156 GB / 200 GB (78%) âš ï¸
  - /var (sda3): 42 GB / 50 GB (84%) âš ï¸

â€¢ NETWORK (eth0):
  - Received: 2.5 Mbps
  - Sent: 0.8 Mbps

â€¢ TEMPERATURE: 48Â°C (normal)

âš ï¸ ATTENTION POINTS:
1. /home approaching 80% - consider cleanup
2. /var at 84% - check logs

Need to analyze anything in particular?
```

*MCP tools used: `check_glances_status()`, `get_cpu_usage()`, `get_memory_usage()`, `get_disk_usage()`, `get_network_stats()`, `get_system_sensors()`*

---

### Example 1.2: Simplified Monitoring

**You**:
```
Just CPU and RAM please
```

**Claude**:
```
ğŸ“Š Quick Stats:

CPU: 15% (Load: 0.6)
RAM: 51% (8.2/16 GB)

All good! ğŸ‘
```

*MCP tools used: `get_cpu_usage()`, `get_memory_usage()`*

---

## ğŸ” Scenario 2: Problem Diagnosis

### Example 2.1: Slow Computer

**You**:
```
My computer has been sluggish for 10 minutes, what's happening?
```

**Claude**:
```
Let me analyze what's slowing down your system...

ğŸ”´ PROBLEM IDENTIFIED!

CPU is at 94% usage - here are the culprits:

TOP 5 RESOURCE-INTENSIVE PROCESSES:
1. âŒ node (PID 3421) - 45% CPU, 2.8 GB RAM
   â””â”€ Command: node --max-old-space-size=4096 build.js
   â””â”€ Started: 12 min ago

2. âŒ chrome (PID 2156) - 28% CPU, 3.2 GB RAM
   â””â”€ 47 tabs open

3. âš ï¸ docker (PID 1234) - 12% CPU, 1.5 GB RAM
   â””â”€ Container: mysql_prod

4. âœ… code (PID 4567) - 5% CPU, 800 MB RAM
5. âœ… spotify (PID 5678) - 4% CPU, 450 MB RAM

ğŸ¯ ANALYSIS:
The Node.js process is performing a build consuming 45% CPU.
Chrome with 47 tabs is making the situation worse.

ğŸ’¡ RECOMMENDATIONS:
1. Urgent: Close some Chrome tabs (will save ~15% CPU)
2. Wait for Node.js build to finish (2-3 min estimated)
3. Optional: Restart MySQL container if slowness persists

Would you like me to monitor progress every 30 seconds?
```

*MCP tools used: `get_cpu_usage()`, `get_top_processes(10)`, `get_process_info(3421)`, `get_process_info(2156)`*

---

### Example 2.2: Memory Saturation

**You**:
```
I'm getting "Out of memory" messages, help me!
```

**Claude**:
```
ğŸš¨ CRITICAL MEMORY ALERT!

CURRENT STATE:
â€¢ RAM: 15.4 GB / 16 GB (96%) âŒ
â€¢ Swap: 3.8 GB / 4 GB (95%) âŒ
â€¢ Available: Only 640 MB

ğŸ”´ PROCESSES CONSUMING MOST RAM:

1. docker (PID 1234) - 4.2 GB
   â””â”€ Container postgres_db
   â””â”€ SUGGESTION: Limit Docker RAM

2. chrome (PID 2345) - 3.8 GB
   â””â”€ 63 tabs open
   â””â”€ ACTION: Close immediately!

3. intellij-idea (PID 5678) - 2.9 GB
   â””â”€ Heap size: 2048m
   â””â”€ SUGGESTION: Reduce -Xmx

4. node (PID 8901) - 2.1 GB
   â””â”€ Multiple active processes

5. firefox (PID 3456) - 1.4 GB

âš¡ IMMEDIATE ACTIONS:
1. âŒ Close Chrome NOW (will free ~4 GB)
2. âš ï¸ Restart IntelliJ with -Xmx1024m
3. ğŸ”„ Restart Postgres container with RAM limit
4. ğŸ§¹ Kill unused Node processes

ğŸ”§ SUGGESTED COMMANDS:
```bash
# Kill Chrome cleanly
killall chrome

# Limit Docker Postgres
docker update --memory=2g postgres_db

# View Node processes
ps aux | grep node
```

Long-term configuration recommended: upgrade to 32 GB RAM
```

*MCP tools used: `get_memory_usage()`, `get_top_processes(15)`, RAM analysis*

---

## ğŸ“ˆ Scenario 3: Temporal Analysis

### Example 3.1: Performance Evolution

**You**:
```
Show me CPU evolution over the last 2 hours
```

**Claude**:
```
ğŸ“Š CPU EVOLUTION - LAST 2 HOURS (120 measurements)

ASCII Chart:
100%|                    â–ˆâ–ˆ                            |
 90%|                   â–ˆâ–ˆâ–ˆâ–ˆ                           |
 80%|                  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          |
 70%|                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         |
 60%|                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        |
 50%|      â–“â–“       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       |
 40%|     â–“â–“â–“â–“     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      â–“â–“             |
 30%|    â–“â–“â–“â–“â–“â–“   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–“â–“â–“â–“            |
 20%|   â–“â–“â–“â–“â–“â–“â–“â–“ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–“â–“â–“â–“â–“â–“           |
 10%|â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“|
  0%|__________________________________________________|
     12:00              13:00              14:00 (now)

ğŸ“ˆ STATISTICS:
â€¢ Average: 28%
â€¢ Minimum: 8% (at 12:15)
â€¢ Maximum: 94% (at 13:23)
â€¢ Current: 15%

ğŸ” NOTABLE EVENTS:

1. âš ï¸ PEAK at 13:23 (94%) - Duration: 8 minutes
   Probable cause: Build or compilation

2. ğŸ“Š Stable usage 12:00-12:45 (~12%)
   Low activity period

3. ğŸ“ˆ Progressive increase 12:45-13:15
   Normal ramp-up

4. âœ… Back to normal since 13:30
   System stabilized

ğŸ’¡ ANALYSIS:
Normal behavior with an isolated peak probably caused by
a batch task. No performance issues detected.

Want to see details of the 13:23 peak?
```

*MCP tools used: `get_plugin_history("cpu", 120)`*

---

### Example 3.2: Disk Trend

**You**:
```
My disk is filling up quickly, how long until it's full?
```

**Claude**:
```
ğŸ“Š PREDICTIVE ANALYSIS - DISK SPACE

CURRENT STATE (/):
â€¢ Used: 285 GB / 500 GB (57%)
â€¢ Available: 215 GB
â€¢ Inodes: 12% used

ğŸ“ˆ HISTORICAL ANALYSIS (last 30 days):
```
Day 1:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 42%
Day 5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 44%
Day 10: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 46%
Day 15: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 49%
Day 20: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 52%
Day 25: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 55%
Day 30: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 57% â† Today
```

ğŸ”® PREDICTIONS:

Average growth: +500 MB/day (~0.1%/day)

â€¢ 70% (350 GB): In ~130 days (April 21, 2026)
â€¢ 80% (400 GB): In ~230 days (July 30, 2026)
â€¢ 90% (450 GB): In ~330 days (November 7, 2026)
â€¢ 95% (475 GB): In ~380 days (December 27, 2026)

ğŸ“ MAIN CONSUMERS:
1. /var/log: 45 GB (application logs)
2. /home/user/Downloads: 38 GB
3. Docker images: 32 GB
4. /tmp: 12 GB

ğŸ’¡ RECOMMENDATIONS:

âœ¨ QUICK ACTIONS (gain: ~80 GB):
```bash
# Clean old logs
sudo journalctl --vacuum-time=7d

# Empty downloads
rm -rf ~/Downloads/old/*

# Remove unused Docker images
docker system prune -a
```

ğŸ“… PLANNING:
â€¢ Short term (OK): Nothing urgent
â€¢ Medium term: Implement automatic log rotation
â€¢ Long term: Disk extension or NAS

You're safe for at least 6 months! ğŸ‘
```

*MCP tools used: `get_plugin_history("fs", 30)`, `get_disk_usage()`*

---

## ğŸ”§ Scenario 4: Advanced Operations

### Example 4.1: Monitoring a Critical Process

**You**:
```
I just launched an important Python script (PID 9876).
Monitor it and let me know if there's a problem.
```

**Claude**:
```
âœ… Monitoring activated for process 9876

ğŸ“ INITIAL INFORMATION:
â€¢ Name: python3
â€¢ Command: python3 data_processing.py --batch-size=1000
â€¢ State: Running
â€¢ Started: 2 seconds ago
â€¢ CPU: 85% (normal for data processing)
â€¢ RAM: 1.2 GB / 16 GB
â€¢ Disk I/O: 45 MB/s read, 12 MB/s write
â€¢ Threads: 4

ğŸ“Š SYSTEM RESOURCES:
â€¢ Global CPU: 89% (your script + others)
â€¢ Available RAM: 14.2 GB (plenty available)
â€¢ Temperature: 62Â°C (normal increase)

âœ… EVERYTHING IS NORMAL

I will monitor:
1. CPU usage (alert if > 98% for 5 min)
2. RAM usage (alert if > 8 GB)
3. Process state (alert if crash)
4. Excessive I/O (alert if > 200 MB/s for 10 min)

[â±ï¸ I'll keep you informed every 5 minutes or in case of anomaly]

ğŸ’¡ TIP: Type "status 9876" for instant update
```

*MCP tools used: `get_process_info(9876)`, `get_cpu_usage()`, `get_memory_usage()`*

---

**5 minutes later...**

**Claude** (automatic update):
```
ğŸ“Š UPDATE - Process 9876

Elapsed time: 5 min 23 sec

State: âœ… Running (all good)
â€¢ CPU: 78% (stable)
â€¢ RAM: 2.1 GB (+900 MB - normal growth)
â€¢ I/O: 38 MB/s (decreasing, end of reading?)
â€¢ Estimated progress: ~25% (based on I/O patterns)

No anomalies detected. Next update in 5 min.
```

---

### Example 4.2: Before/After Comparison

**You**:
```
I'm going to optimize my MySQL config. Note the current state,
I'll tell you when to compare.
```

**Claude**:
```
ğŸ“¸ SNAPSHOT SAVED - MySQL Performance

TIMESTAMP: 2025-12-11 14:23:45

ğŸ” MYSQL STATE (PID 1234):
â€¢ CPU: 23%
â€¢ RAM: 2.8 GB
â€¢ Threads: 156
â€¢ Connections: 48 active

ğŸ“Š SYSTEM METRICS:
â€¢ Global CPU: 45%
â€¢ Total RAM: 12.1 GB / 16 GB (75%)
â€¢ Load average: 1.8, 2.1, 1.9
â€¢ Disk I/O: 85 MB/s

ğŸ“ˆ QUERIES (via process analysis):
â€¢ Queries/sec: ~450 (estimated via CPU patterns)
â€¢ I/O operations: High

âœ… Baseline saved!
Type "compare mysql" when you're done with the optimization.
```

---

**After optimization...**

**You**:
```
compare mysql
```

**Claude**:
```
ğŸ“Š BEFORE/AFTER COMPARISON - MySQL Optimization

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric          â”‚ Before   â”‚ After    â”‚ Î”        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CPU Usage       â”‚ 23%      â”‚ 14%      â”‚ -39% âœ…  â”‚
â”‚ RAM Usage       â”‚ 2.8 GB   â”‚ 2.1 GB   â”‚ -25% âœ…  â”‚
â”‚ Threads         â”‚ 156      â”‚ 98       â”‚ -37% âœ…  â”‚
â”‚ Connections     â”‚ 48       â”‚ 45       â”‚ -6%  âœ…  â”‚
â”‚ Load Avg (1m)   â”‚ 1.8      â”‚ 1.2      â”‚ -33% âœ…  â”‚
â”‚ Disk I/O        â”‚ 85 MB/s  â”‚ 62 MB/s  â”‚ -27% âœ…  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ‰ EXCELLENT RESULTS!

ğŸ’¡ GAINS ACHIEVED:
â€¢ CPU saved: 9 percentage points
â€¢ RAM freed: 700 MB
â€¢ System load reduced by 33%
â€¢ I/O lightened by 23 MB/s

ğŸ“ˆ PERFORMANCE:
The optimization is very effective! The system breathes better
and should handle more load.

âœ… RECOMMENDATION:
Keep this configuration. Monitor for 24h to
confirm stability.

Would you like me to generate a complete report?
```

*MCP tools used: `get_process_info()`, temporal snapshots, comparisons*

---

## ğŸ³ Scenario 5: Docker and Containers

### Example 5.1: Docker Overview

**You**:
```
Give me a status of my Docker containers
```

**Claude**:
```
ğŸ³ DOCKER CONTAINERS - OVERVIEW

ğŸ“Š SUMMARY:
â€¢ Total containers: 5
â€¢ Running: 4 âœ…
â€¢ Stopped: 1 âš ï¸

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. âœ… webapp_prod (nginx:alpine)
   â”œâ”€ Status: Running (uptime: 12d 5h)
   â”œâ”€ CPU: 2% (very low)
   â”œâ”€ RAM: 125 MB / 512 MB limit (24%)
   â”œâ”€ Network: â†“ 5.2 Mbps  â†‘ 1.8 Mbps
   â””â”€ Health: Healthy

2. âœ… postgres_db (postgres:14)
   â”œâ”€ Status: Running (uptime: 12d 5h)
   â”œâ”€ CPU: 15% (active)
   â”œâ”€ RAM: 1.8 GB / 4 GB limit (45%)
   â”œâ”€ Network: â†“ 2.1 Mbps  â†‘ 3.4 Mbps
   â”œâ”€ I/O: 85 MB/s read, 42 MB/s write
   â””â”€ Health: Healthy

3. âœ… redis_cache (redis:7-alpine)
   â”œâ”€ Status: Running (uptime: 12d 5h)
   â”œâ”€ CPU: 1%
   â”œâ”€ RAM: 89 MB / 256 MB limit (35%)
   â”œâ”€ Network: â†“ 0.8 Mbps  â†‘ 0.3 Mbps
   â””â”€ Health: Healthy

4. âœ… worker_queue (python:3.11-slim)
   â”œâ”€ Status: Running (uptime: 3h 22m)
   â”œâ”€ CPU: 8%
   â”œâ”€ RAM: 340 MB / 1 GB limit (34%)
   â”œâ”€ Network: â†“ 0.2 Mbps  â†‘ 0.1 Mbps
   â””â”€ Health: Healthy

5. âš ï¸ backup_service (custom/backup:latest)
   â”œâ”€ Status: Exited (code 0) - 2h ago
   â”œâ”€ Last seen: OK (normal, scheduled task)
   â””â”€ Note: Launches automatically

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ TOTAL DOCKER USAGE:
â€¢ CPU: 26% (all containers)
â€¢ RAM: 2.36 GB / 5.77 GB allocated (41%)
â€¢ Network: â†“ 8.3 Mbps  â†‘ 5.6 Mbps

ğŸ’¾ IMAGES:
â€¢ Total size: 4.2 GB
â€¢ Unused images: 1.8 GB (cleanable)

âœ… OVERALL HEALTH: Excellent
All critical services are operational.

ğŸ’¡ SUGGESTION:
```bash
# Clean unused images
docker image prune -a
# Estimated gain: ~1.8 GB
```
```

*MCP tools used: `get_plugin_data("docker")`, Docker process analysis*

---

## ğŸ“Š Scenario 6: Reports and Exports

### Example 6.1: Weekly Report

**You**:
```
Generate a system health report for my DevOps team
```

**Claude**:
```markdown
# ğŸ“Š System Health Report
**Period**: Week of December 4-11, 2025
**Server**: prod-server-01
**Generated on**: December 11, 2025 at 2:30 PM

---

## ğŸ¯ Executive Summary

âœ… **Overall Status**: HEALTHY
âš ï¸ **Attention Points**: 2
âŒ **Critical Issues**: 0

---

## ğŸ“ˆ Key Metrics

### CPU
- **Average usage**: 28%
- **Maximum peak**: 94% (Dec 8 at 3:23 PM)
- **Load average**: 1.2 / 1.5 / 1.4
- **Trend**: â†—ï¸ +5% vs previous week

### Memory
- **Average usage**: 12.2 GB / 16 GB (76%)
- **Maximum peak**: 15.1 GB (94%) on Dec 9
- **Swap used**: Minimal (< 500 MB)
- **Trend**: â†’ Stable

### Disks
| Partition | Used | Capacity | Evolution |
|-----------|------|----------|-----------|
| /         | 285 GB | 500 GB (57%) | +2 GB/week |
| /home     | 156 GB | 200 GB (78%) | +5 GB/week âš ï¸ |
| /var      | 42 GB | 50 GB (84%) | +1 GB/week âš ï¸ |

### Network
- **Average traffic**: â†“ 25 Mbps / â†‘ 12 Mbps
- **Inbound peak**: 180 Mbps (backup on Dec 10)
- **Packet loss**: 0%
- **Average latency**: < 1ms

---

## âš ï¸ Attention Points

### 1. Disk space /home (78%)
- **Priority**: Medium
- **Action**: Cleanup recommended within 30 days
- **Estimate**: Saturation in ~4 months at current rate

### 2. Disk space /var (84%)
- **Priority**: Medium
- **Action**: Implement log rotation
- **Detail**: 28 GB of logs in /var/log

---

## ğŸ¯ Service Performance

### Docker Applications
| Service | Uptime | Avg CPU | Avg RAM | Status |
|---------|--------|---------|---------|--------|
| webapp_prod | 99.9% | 2% | 125 MB | âœ… |
| postgres_db | 100% | 12% | 1.8 GB | âœ… |
| redis_cache | 100% | 1% | 89 MB | âœ… |
| worker_queue | 98.2% | 8% | 340 MB | âœ… |

**Note**: worker_queue restarted 1x (planned maintenance)

---

## ğŸ“Š Incidents & Events

### Notable events
1. **Dec 8, 3:23 PM** - CPU peak 94% (duration: 8 min)
   - Cause: Scheduled application build
   - Impact: None

2. **Dec 9, 3:15 AM** - RAM usage 94%
   - Cause: Database backup
   - Impact: None, resolved automatically

3. **Dec 10, 2:00 AM** - Network peak 180 Mbps
   - Cause: Offsite backup
   - Impact: None

**Total alerts**: 3 (all resolved)

---

## ğŸ’¡ Recommendations

### Short term (this week)
1. âœ… Implement automatic log rotation
   ```bash
   sudo logrotate -f /etc/logrotate.conf
   ```

2. âœ… Clean /home/user/Downloads (estimated gain: 35 GB)

### Medium term (this month)
1. ğŸ“‹ Plan thorough /home cleanup
2. ğŸ“‹ Evaluate RAM upgrade need (frequently approaches 90%)

### Long term (Q1 2026)
1. ğŸ’¾ Extend disk capacity or implement NAS
2. ğŸ”„ Migrate to server with 32 GB RAM

---

## ğŸ“ Contacts & Support
**Team**: DevOps
**Contact**: devops@company.com
**Documentation**: wiki.company.com/infra

---

*Report generated automatically via Glances MCP*
```

Would you like this report in PDF or sent via email?
```

*MCP tools used: `get_all_system_stats()`, 7-day historical analysis, aggregation*

---

## ğŸ® Scenario 7: Conversational Interactions

### Example 7.1: Natural Dialogue

**You**:
```
My computer is heating up a lot, is that normal?
```

**Claude**:
```
Let me check the temperature sensors...

ğŸŒ¡ï¸ CURRENT TEMPERATURE: 78Â°C

âš ï¸ That's indeed elevated! Normal temperature is
between 40-60Â°C at idle, and up to 70Â°C under load.

Let's see what's causing this heat...

ğŸ”¥ ANALYSIS:
â€¢ CPU: 89% usage â†’ Main heat source
â€¢ Fans: 2800 RPM (85% of max speed)
â€¢ Resource-intensive processes detected:
  1. blender (3D rendering) - 52% CPU
  2. chrome (23 tabs) - 25% CPU
  3. docker - 12% CPU

ğŸ’¡ EXPLANATION:
Blender is doing a 3D render, heating is normal!
The fans are spinning fast to compensate.

POSSIBLE ACTIONS:
1. âœ… Let the render finish (fans are doing their job)
2. ğŸ’¨ Make sure vents aren't blocked
3. ğŸ§¹ Clean fans if you haven't done so recently
4. âŒ Avoid using Chrome in parallel (closing = -10Â°C)

Want me to monitor the temperature and alert you if it
exceeds 85Â°C?
```

---

**You**:
```
Yes please monitor it
```

**Claude**:
```
âœ… Temperature monitoring activated!

Alert threshold: 85Â°C
Current temperature: 78Â°C

I'll notify you if:
- Temperature > 85Â°C (critical)
- Temperature > 80Â°C for > 10 min (attention)
- Fans reach 100% (saturation)

ğŸ§˜ Meanwhile, everything is under control.
The fans are managing heat dissipation well.
```

---

## ğŸ¤– Scenario 8: Automation and Scripts

### Example 8.1: Monitoring Script

**You**:
```
Create a script that checks every hour if
my disks exceed 85% and sends me an email if so
```

**Claude**:
```python
#!/usr/bin/env python3
"""
Disk monitoring script with email alerts
Checks disk space every hour via Glances API
"""

import requests
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import time
from datetime import datetime

# Configuration
GLANCES_URL = "http://localhost:61208"
THRESHOLD = 85  # Threshold in %
EMAIL_FROM = "monitoring@your-server.com"
EMAIL_TO = "you@example.com"
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587
CHECK_INTERVAL = 3600  # 1 hour in seconds

def check_disk_usage():
    """Check disk usage via Glances API"""
    try:
        response = requests.get(f"{GLANCES_URL}/api/4/fs")
        response.raise_for_status()
        disks = response.json()

        alerts = []
        for disk in disks:
            usage_percent = disk.get('percent', 0)
            mount_point = disk.get('mnt_point', 'Unknown')

            if usage_percent >= THRESHOLD:
                alerts.append({
                    'mount_point': mount_point,
                    'percent': usage_percent,
                    'size': disk.get('size', 0) / (1024**3),  # GB
                    'used': disk.get('used', 0) / (1024**3),  # GB
                    'free': disk.get('free', 0) / (1024**3),  # GB
                })

        return alerts
    except Exception as e:
        print(f"Error during check: {e}")
        return None

def send_email_alert(alerts):
    """Send email alert"""
    try:
        msg = MIMEMultipart()
        msg['From'] = EMAIL_FROM
        msg['To'] = EMAIL_TO
        msg['Subject'] = f"âš ï¸ Disk Space Alert - {len(alerts)} saturated partition(s)"

        # Email body
        body = f"""
        <html>
        <body>
            <h2>ğŸš¨ Disk Space Alert</h2>
            <p><strong>Date:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>Threshold:</strong> {THRESHOLD}%</p>

            <h3>Affected partitions:</h3>
            <table border="1" style="border-collapse: collapse; padding: 10px;">
                <tr>
                    <th>Mount point</th>
                    <th>Usage</th>
                    <th>Used</th>
                    <th>Free</th>
                    <th>Total</th>
                </tr>
        """

        for alert in alerts:
            body += f"""
                <tr>
                    <td>{alert['mount_point']}</td>
                    <td style="color: red;"><strong>{alert['percent']:.1f}%</strong></td>
                    <td>{alert['used']:.1f} GB</td>
                    <td>{alert['free']:.1f} GB</td>
                    <td>{alert['size']:.1f} GB</td>
                </tr>
            """

        body += """
            </table>

            <h3>Recommended actions:</h3>
            <ul>
                <li>Clean temporary files</li>
                <li>Check for large logs</li>
                <li>Delete unnecessary files</li>
                <li>Consider capacity extension</li>
            </ul>

            <p><em>This message was automatically generated by the monitoring script.</em></p>
        </body>
        </html>
        """

        msg.attach(MIMEText(body, 'html'))

        # Send email
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
            server.starttls()
            server.login(EMAIL_FROM, "your_password")  # To configure
            server.send_message(msg)

        print(f"âœ… Alert email sent for {len(alerts)} partition(s)")
        return True
    except Exception as e:
        print(f"âŒ Error sending email: {e}")
        return False

def main():
    """Main monitoring loop"""
    print("ğŸš€ Starting disk monitoring...")
    print(f"   Threshold: {THRESHOLD}%")
    print(f"   Interval: {CHECK_INTERVAL}s ({CHECK_INTERVAL/3600}h)")
    print(f"   Email: {EMAIL_TO}")
    print()

    while True:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Checking...")

        alerts = check_disk_usage()

        if alerts is None:
            print("   âš ï¸ Glances connection error")
        elif len(alerts) > 0:
            print(f"   ğŸš¨ {len(alerts)} partition(s) above threshold!")
            for alert in alerts:
                print(f"      - {alert['mount_point']}: {alert['percent']:.1f}%")
            send_email_alert(alerts)
        else:
            print("   âœ… All disks OK")

        print(f"   ğŸ’¤ Next check in {CHECK_INTERVAL/3600}h...\n")
        time.sleep(CHECK_INTERVAL)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Stopping monitoring")
```

ğŸ“‹ **INSTALLATION INSTRUCTIONS:**

1. Install dependencies:
```bash
pip install requests
```

2. Configure the script:
```python
EMAIL_FROM = "your-email@example.com"
EMAIL_TO = "recipient@example.com"
# Also configure SMTP credentials
```

3. Run the script:
```bash
# Foreground (test)
python3 disk_monitor.py

# Background
nohup python3 disk_monitor.py > monitor.log 2>&1 &

# Or with systemd (production)
sudo systemctl start disk-monitor
```

4. Systemd configuration (optional):
```bash
# Create /etc/systemd/system/disk-monitor.service
sudo nano /etc/systemd/system/disk-monitor.service
```

Would you also like the complete systemd configuration?
```

*Conceptual MCP tools: API integration demonstration*

---

## ğŸ“ Scenario 9: Learning and Explanations

### Example 9.1: Understanding Metrics

**You**:
```
What is Load Average and why is mine at 2.5?
```

**Claude**:
```
ğŸ“š EXPLANATION - Load Average

Load Average represents the average system load over 3 periods:
â€¢ 1 minute
â€¢ 5 minutes
â€¢ 15 minutes

ğŸ” YOUR SYSTEM CURRENTLY:
Load Average: 2.5, 2.3, 1.8
Number of CPUs: 4 cores

ğŸ’¡ HOW TO INTERPRET IT:

Load Average indicates the average number of processes waiting
for execution. For a 4-core system:

â€¢ 0.0 - 1.0  â†’  Underutilized system âœ…
â€¢ 1.0 - 4.0  â†’  Normal usage âœ…
â€¢ 4.0 - 8.0  â†’  Loaded system âš ï¸
â€¢ > 8.0      â†’  Overloaded system âŒ

ğŸ¯ YOUR CASE (2.5):
Load: 2.5 / CPUs: 4 = 62.5% load

This is PERFECTLY NORMAL! Your system is using ~63% of its
capacity, with 37% margin remaining.

ğŸ“Š DETAIL:
â€¢ Load 1m: 2.5 (current load)
â€¢ Load 5m: 2.3 (slight increase)
â€¢ Load 15m: 1.8 (upward trend over 15min)

ğŸ“ˆ TREND:
Load is gradually increasing. Currently active processes:
1. python (build) - 45% CPU
2. chrome - 28% CPU
3. docker - 12% CPU

ğŸ“ GOLDEN RULE:
Load Average < Number of CPUs = All good!

In your case: 2.5 < 4 âœ…

Questions about other metrics?
```

---
